#!python

"""
Nino 3.4 index (ONI)

The script calculates the ONI time series

CMIP5 model has been downloaded to the server with the data structure setting as
"~/CMIP5/product/institute/model/experiment/
    time_frequency/realm/cmor_table/ensemble/variable/"

The data storing structure is defined by the wget script generated by the
RESTful API provided by the ESGF.
Detail instructure of how to utilize this API can be find at
https://www.earthsystemcog.org/projects/cog/esgf_search_restful_api

ONI uses the CMIP5 model output "tos" which is representing
the sea surface temperaturesea (SST) measured over the ocean.
The variable is also in the skin temperature which has the output name of "ts".

ONI:
Warm (red) and cold (blue) periods based on a threshold of +/- 0.5C for the
Oceanic Nino Index (ONI) [3 month running mean of ERSST.v5 SST anomalies
average over the Pacific Ocean tropic region in
the Nino 3.4 region (5N-5S, 120-170W)], based on centered 30-year base
periods updated every 5 years.
(http://origin.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/ONI_v5.php)

"""


import os
import sys
import pyproj
import datetime
import numpy as np
import xarray as xr
import pandas as pd
from sphere_area import cal_area
from shapely.ops import transform
from functools import partial
from shapely.geometry.polygon import Polygon



#### Define the base directory
basedir=os.getcwd()
databasedir=basedir+'/data/'

#### read in the model names
model_info=pd.read_excel('%s/info/CMIP5_Models_Grid_Resolution_vERC.xlsx'\
                        %(basedir),header=0)
model_name=model_info['CMIP5 Model']
institude_name=model_info['Institute'].unique()

model_ens=pd.read_excel('%s/info/CMIP5_ensembles.xlsx'%(basedir),header=0)
all_ensemble=model_ens['ensemble_members']


#### function calculate ONI in CMIP model
def cmip_oni(databasedir,p,i,m,e,t,r,c,ens,v,starttime,endtime):
    pickfile=[]
    pickfile_syear=[]
    datadir=os.path.join(databasedir,"CMIP5",p,i,m,e,t,r,c,ens,v)
    if m in ['EC-EARTH'] and e in ['rcp85']:
        datadir=os.path.join(databasedir,"CMIP5",p,i,m,e,t,r,c,ens,'hfds')
    if os.path.isdir(datadir):
        print datadir
        for file in os.listdir(datadir):
            if file.endswith(".nc"):
                if file.startswith(v):
                    syear=np.int(file[-16:-16+4])
                    smon=np.int(file[-12:-12+2])
                    fyear=np.int(file[-9:-9+4])
                    fmon=np.int(file[-5:-5+2])
                    if (syear >= starttime and syear <= endtime)\
                      or (fyear >= starttime and fyear <= endtime) :
                        pickfile_syear.append(syear)
                        pickfile.append(file)
    else :
        return None, None, None

    if len(pickfile)>0:
        #### sort the file order by year
        # through linking the syear array with filename array
        pickfile_syear, pickfile = \
        (list(t) for t in zip(*sorted(zip(pickfile_syear, pickfile))))

        #### calculate area for Nino3.4 region
        datafile=os.path.join(datadir,pickfile[0])
        try:
            ds_tos=xr.open_dataset(datafile)
        except IOError:
            print "-----"
            print "-First file broken (skip entire experiement)"
            print datafile
            print "-----"
            return datadir,pickfile,None
        except ValueError:
            print "Time dimension cannot be decoded in xarray"
            print "because the time array is out of range "
            print "please make sure the time array is rebased correctly"
            ds_tos=xr.open_dataset(datafile,decode_times=False)
            print "current unit: ",ds_tos.time.units
            ds_tos.time.attrs['units']='days since %i-01-01'%(pickfile_syear[0])
            ds_tos.time.values=\
                xr.cftime_range("%i"%(pickfile_syear[0]), \
                periods=ds_tos.time.values.size, freq='MS', \
                calendar='noleap')

        #### define Nino3.4 region
        # CMIP5 lon range from 0-360
        lonrange_nino34=np.array([-170.+360,-120.+360.])
        latrange_nino34=np.array([-5.,5.])

        ## check ocean model indexing
        # three type of indexing in CMIP5 models
        # 1. i,j (lon,lat=>2D)
        # 2. rlon,rlat (lon,lat=>2D)
        # 3. lon,lat (lon,lat=>1D)
        if len(ds_tos.lon.shape) == 1 and len(ds_tos.lat.shape) == 1:
            print " => Regular grid"
            ds_tos.lon.values[np.where(ds_tos.lon.values<0)]+=360.
            ds_tos.lon_bnds[np.where(ds_tos.lon_bnds.values<0)]+=360.
            lon,lat=np.meshgrid(ds_tos.lon.values,ds_tos.lat.values)
            area=np.zeros(lon.shape)

            for lon_ind in range(len(ds_tos.lon)):
                dlon=np.abs(ds_tos.lon_bnds[lon_ind][1].values\
                            -ds_tos.lon_bnds[lon_ind][0].values)
                llon=ds_tos.lon.values[lon_ind]
                for lat_ind in range(len(ds_tos.lat)):
                    dlat=np.abs(ds_tos.lat_bnds[lat_ind][1].values\
                                -ds_tos.lat_bnds[lat_ind][0].values)
                    llat=ds_tos.lat.values[lat_ind]
                    if llon > lonrange_nino34[0] \
                        and llon < lonrange_nino34[1] \
                        and llat > latrange_nino34[0] \
                        and llat < latrange_nino34[1]:
                        area[lat_ind,lon_ind]=\
                        cal_area(llon,llat,dlon,dlat)['area']/(1.e4) # cm^2 to m^2

            da_area=xr.DataArray(area\
                    ,coords={'lat':ds_tos.lat.values,'lon':ds_tos.lon.values}\
                    ,dims=['lat', 'lon'])
            print " => lon, lat as coord index"

        elif len(ds_tos.lon.shape) == 2 and len(ds_tos.lat.shape) == 2:
            print " => Rotate or index grid"
            ds_tos.lon.values[np.where(ds_tos.lon.values<0)]+=360.

            try :
                ds_tos.lon_vertices.values[np.where(ds_tos.lon_vertices.values<0)]+=360.
                print " => lon_vertices, lat_vertices to calculate area"
                lat=ds_tos.lat.values
                lon=ds_tos.lon.values
                area=np.zeros(lon.shape)

                for j_ind in range(ds_tos.lon.shape[1]):
                    for i_ind in range(ds_tos.lon.shape[0]):
                        llon=ds_tos.lon.values[i_ind,j_ind]
                        llat=ds_tos.lat.values[i_ind,j_ind]

                        if llon > lonrange_nino34[0] \
                         and llon < lonrange_nino34[1] \
                         and llat > latrange_nino34[0] \
                         and llat < latrange_nino34[1]:
                            vertices=[]
                            for vt in range(len(ds_tos.vertices)):
                                vertices.append(\
                                  (ds_tos.lon_vertices.values[i_ind,j_ind,vt]\
                                  ,ds_tos.lat_vertices.values[i_ind,j_ind,vt]))
                            vertices.append(\
                              (ds_tos.lon_vertices.values[i_ind,j_ind,0]\
                              ,ds_tos.lat_vertices.values[i_ind,j_ind,0]))

                            # using vertice point to create polygon obj.
                            geom = Polygon(vertices)

                            ## using partial to create function for multiple projection jobs
                            # func : pyproj.transform
                            # 1st proj : WGS84 bound -180 180 -90 90
                            # 2nd proj : Albert Equal Area projection
                            projecting=partial(pyproj.transform,\
                                               pyproj.Proj(init='EPSG:4326'),\
                                               pyproj.Proj(proj='aea',\
                                                           lat1=geom.bounds[1],\
                                                           lat2=geom.bounds[3])\
                                               )
                            geom_area = transform(projecting,geom)
                            area[i_ind,j_ind] = geom_area.area     # area in m^2
                try:
                    da_area=xr.DataArray(area,\
                                         coords={'rlat':ds_tos.rlat.values,\
                                                 'rlon':ds_tos.rlon.values,\
                                                 'lon':(('rlat','rlon'),lon),\
                                                 'lat':(('rlat','rlon'),lat)},\
                                         dims=['rlat', 'rlon'])
                    print " => rlon, rlat as coord index"

                except AttributeError:
                    da_area=xr.DataArray(area,\
                                         coords={'j':ds_tos.j.values,\
                                                 'i':ds_tos.i.values,\
                                                 'lon':(('j','i'),lon),\
                                                 'lat':(('j','i'),lat)},\
                                         dims=['j', 'i'])
                    print " => i,j as coord index"

            except AttributeError:
                print " => rlon_bnd, rlat_bnd to calculate area"
                lat=ds_tos.lat.values
                lon=ds_tos.lon.values
                area=np.zeros(lon.shape)
                for lon_ind in range(len(ds_tos.rlon)):
                    dlon=np.abs(ds_tos.rlon_bnds[lon_ind][1].values\
                               -ds_tos.rlon_bnds[lon_ind][0].values)
                    llon=ds_tos.rlon.values[lon_ind]
                    if llon < 0.: llon+=360.
                    for lat_ind in range(len(ds_tos.rlat)):
                        dlat=np.abs(ds_tos.rlat_bnds[lat_ind][1].values\
                                   -ds_tos.rlat_bnds[lat_ind][0].values)
                        llat=ds_tos.rlat.values[lat_ind]
                        if llon > lonrange_nino34[0] \
                         and llon < lonrange_nino34[1] \
                         and llat > latrange_nino34[0] \
                         and llat < latrange_nino34[1]:
                            area[lat_ind,lon_ind]=\
                            cal_area(llon,llat,dlon,dlat)['area']/(1.e4) # cm^2 to m^2
                print " => rlon, rlat as coord index"
                da_area=xr.DataArray(area,\
                                     coords={'rlat':ds_tos.rlat.values,\
                                             'rlon':ds_tos.rlon.values,\
                                             'lon':(('rlat','rlon'),lon),\
                                             'lat':(('rlat','rlon'),lat)},\
                                     dims=['rlat', 'rlon'])

        nino34_area_sum=da_area.sum()
        print ("Finish Calculate the area of each grid")

        # dealing with individual file
        dd_index=0
        for file in pickfile:
            datafile=os.path.join(datadir,file)
            try:
                ds_tos=xr.open_dataset(datafile)
                ds_tos.lon.values[np.where(ds_tos.lon.values<0)]+=360.
            except IOError:
                print "-----"
                print "- file broken:",file
                print "-----"
                break
            except ValueError:
                print "Time dimension cannot be decoded in xarray"
                print "because the time array is out of range "
                print "current unit: ",ds_tos.time.units
                print "please make sure the time array is rebased correctly"
                ds_tos=xr.open_dataset(datafile,decode_times=False)
                ds_tos.time.attrs['units']=\
                                'days since %i-01-01'%(pickfile_syear[dd_index])
                print "change to unit: ",ds_tos.time.units
                ds_tos.time.values=\
                   xr.cftime_range("%i"%(pickfile_syear[dd_index]), \
                                   periods=ds_tos.time.values.size, \
                                   freq='MS', \
                                   calendar='noleap')
                dd_index+=1

            # area weighted and change unit from K to Celcius
            da_tos_areaweighted=(ds_tos.tos-273.15)*da_area

            # sometime the model output is stored in the "wrong" unit
            #   (not K but degree C) e.g. CM2.1
            if (da_tos_areaweighted).sum(skipna=True) < 0. :
                da_tos_areaweighted=ds_tos.tos*da_area

            # calculate the 3-month running mean defined by NOAA ONI
            if file == pickfile[0]:
                da_tos_aw_concat=da_tos_areaweighted.copy()
            else :
                da_temp=da_tos_areaweighted.copy()
                da_tos_aw_concat=xr.concat([da_tos_aw_concat,da_temp],dim='time')

        da_tos_aw_concat_rmean3=da_tos_aw_concat.rolling(dim={"time":3},\
                                                         min_periods=3,\
                                                         center=True).mean()
        da_nino34=da_tos_aw_concat_rmean3.sum(\
                                         dim=[da_tos_aw_concat_rmean3.dims[1],\
                                              da_tos_aw_concat_rmean3.dims[2]],\
                                         skipna=True)/nino34_area_sum
        da_nino34.values[np.where(da_nino34.values<1E-9)]=np.nan

        #### create timestamp for easy plotting in xarray
        timestamp=[]
        for tt in range(len(da_nino34.time.values)):
            try:
              timestamp.append(datetime.datetime(\
                                        da_nino34.time.values[tt].year,\
                                        da_nino34.time.values[tt].month,\
                                        da_nino34.time.values[tt].day))
            except AttributeError:
              # Ori time is in np.datetime64
              timestamp.append(datetime.datetime(\
                                        da_nino34['time.year'].values[tt],\
                                        da_nino34['time.month'].values[tt],\
                                        da_nino34['time.day'].values[tt]))

        #### cropping the time series
        ind=[]
        timestamp_crop=[]
        for tt in range(len(timestamp)):
            if timestamp[tt].year >= starttime \
            and timestamp[tt].year <= endtime:
                ind.append(tt)
                timestamp_crop.append(timestamp[tt])


        #### store cropped time series in xr.Dataset
        ds_nino34=xr.Dataset()
        da_nino34_new=xr.DataArray(da_nino34.values[np.array(ind)],\
                                   coords={'time':timestamp_crop},\
                                   dims=['time'])
        ds_nino34['nino34']=da_nino34_new


        #### calculate climatology
        clim=np.zeros(12)
        clim_count=np.zeros(12)
        for mon in range(12):
            for tind in range(len(ds_nino34['time'].values)):
                try:
                    ds_nino34_time=ds_nino34['time'].values[tind].month
                except AttributeError:
                    ds_nino34_time=ds_nino34['time.month'].values[tind]
                if ds_nino34_time == mon+1 :
                    if ~np.isnan(ds_nino34.nino34.isel(time=tind)):
                        clim[mon]+=ds_nino34.nino34.isel(time=tind)
                        clim_count[mon]+=1
        clim=clim/clim_count

        #### remove climatology
        nino34_noclim=np.zeros(len(ds_nino34['time'].values))
        for mon in range(12):
            for tind in range(len(ds_nino34['time'].values)):
                try:
                    ds_nino34_time=ds_nino34['time'].values[tind].month
                except AttributeError:
                    ds_nino34_time=ds_nino34['time.month'].values[tind]
                if ds_nino34_time == mon+1 :
                    nino34_noclim[tind]=\
                                      ds_nino34.nino34.isel(time=tind)-clim[mon]


        da_nino34_noclim=xr.DataArray(nino34_noclim,\
                                      coords={'time':timestamp_crop},\
                                      dims=['time'])
        ds_nino34['nino34_noclim']=da_nino34_noclim

        return datadir,pickfile,ds_nino34



if __name__ == '__main__':

    if len(sys.argv)<1 :
        #### option setting (to find data in the corresponding directory)
        # -- RCP run
        product=['output1']
        institute=institude_name
        # model=model_name
        model=['CCSM4']
        experiment=['rcp45']
        time_frequency=['mon']
        realm=['ocean']
        cmor_table=['Omon']
        ensemble=['r1i1p1']
        variable=['tos']

        starttime=2006
        endtime=2100


        # #### option setting (to find data in the corresponding directory)
        # # -- historical run
        # product=['output1']
        # institute=institude_name
        # model=model_name
        # experiment=['historical']
        # time_frequency=['mon']
        # realm=['ocean']
        # cmor_table=['Omon']
        # ensemble=all_ensemble
        # variable=['tos']

        # starttime=1850
        # endtime=2005

    elif len(sys.argv)==12:
        product=[str(sys.argv[1])]
        institute=[str(sys.argv[2])]
        model=[str(sys.argv[3])]
        experiment=[str(sys.argv[4])]
        time_frequency=[str(sys.argv[5])]
        realm=[str(sys.argv[6])]
        cmor_table=[str(sys.argv[7])]
        ensemble=[str(sys.argv[8])]
        variable=[str(sys.argv[9])]
        starttime=int(sys.argv[10])
        endtime=int(sys.argv[11])


    # find data in the corresponding directory
    basedir=os.getcwd()
    for p in product:
     for i in institute:
      for m in model:
       for e in experiment:
        for t in time_frequency:
         for r in realm:
          for c in cmor_table:
           for ens in ensemble:
            for v in variable:

                datadir,pickfile,ds_nino34=\
                    cmip_oni(databasedir,p,i,m,e,t,r,c,ens,v,starttime,endtime)

                if ds_nino34 is not None :
                    try :
                        ds_nino34.to_netcdf(\
                            os.path.join(datadir,'nino3.4_%s%i_%i.nc'\
                            %(pickfile[0][:-16],starttime,endtime)),mode='w')
                    except IOError:
                        os.remove(os.path.join(datadir,'nino3.4_%s%i_%i.nc'\
                                        %(pickfile[0][:-16],starttime,endtime)))
                        ds_nino34.to_netcdf(\
                            os.path.join(datadir,'nino3.4_%s%i_%i.nc'\
                            %(pickfile[0][:-16],starttime,endtime)),mode='w')
